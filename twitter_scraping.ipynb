{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import nltk\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import swifter\n",
    "\n",
    "\n",
    "import emoji\n",
    "# from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a list to append all tweet attributes(data)\n",
    "attributes_container = []\n",
    "Q = '(sambo AND polisi) OR (joshua AND polisi)'\n",
    "Q2 = 'polisi AND kanjuruhan'\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(Q2 + ' since:2022-10-01 until:2022-10-16 -filter:retweets -filter:links').get_items()):\n",
    "    if i > 10000:\n",
    "        break\n",
    "    attributes_container.append([tweet.date, tweet.likeCount, tweet.content])\n",
    "\n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df = pd.DataFrame(attributes_container, columns=[\n",
    "                         \"Date Created\", \"Number of Likes\", \"Tweets\"])\n",
    "tweets_df2 = pd.DataFrame(attributes_container, columns=[\n",
    "                          \"Date Created\", \"Number of Likes\", \"Tweets\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df\n",
    "# tweets_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df.to_csv('10K sambo josua polisi.csv')  \n",
    "# tweets_df2.to_csv('10k2_'+Q2 + '.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('10k_polisi AND kanjuruhan.csv')\n",
    "df1 = df1.drop(columns=['Unnamed: 0', 'Date Created', 'Number of Likes'])\n",
    "\n",
    "df2 = pd.read_csv('10K sambo josua polisi.csv')\n",
    "df2 = df2.drop(columns=['Unnamed: 0', 'Date Created', 'Number of Likes'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('@[^\\s]+','',text)\n",
    "    text = re.sub('http[^\\s]+','',text)\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('[()!?]', ' ', text)\n",
    "    text = re.sub(\"[^a-z0-9]\",\" \", text)\n",
    "    text = re.sub('\\[.*?\\]',' ', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "df1['Tweets'] = df1['Tweets'].apply(clean_text)\n",
    "df2['Tweets'] = df2['Tweets'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sama mas saya pikir fokusnya sama bobroknya ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haduh polisi lagi yg ditonjolkan polisi dah n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>membuat konsorsium judi menjadi sindikat narko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yg gak punya wibawa ya jokowi dan mempora ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ditambah lg dgn tembakan gas air mata k tribun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>seuporter merasa benar turun k lapang kanjuruh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>penonton salah polisi salah  semuanya salah di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>ini waktu  di gbt setelah persebaya kalah law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>citra polisi indonesia bisa hancur jika kasus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>tragedi kanjuruhan adalah akibat akumulasi kes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets\n",
       "0      sama mas saya pikir fokusnya sama bobroknya ke...\n",
       "1       haduh polisi lagi yg ditonjolkan polisi dah n...\n",
       "2      membuat konsorsium judi menjadi sindikat narko...\n",
       "3        yg gak punya wibawa ya jokowi dan mempora ma...\n",
       "4      ditambah lg dgn tembakan gas air mata k tribun...\n",
       "...                                                  ...\n",
       "9996   seuporter merasa benar turun k lapang kanjuruh...\n",
       "9997   penonton salah polisi salah  semuanya salah di...\n",
       "9998    ini waktu  di gbt setelah persebaya kalah law...\n",
       "9999   citra polisi indonesia bisa hancur jika kasus ...\n",
       "10000  tragedi kanjuruhan adalah akibat akumulasi kes...\n",
       "\n",
       "[10001 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>keren jokowi tangkap penjahat kakap kemaren a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dipikirpikir pantesan polisi tahuntahun belaka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setelah kasus sambo yang mayan ribet banyak  p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bubarkan  institusi  kepolisian  copot  kapolr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>memang kalau jadi polisi baik karir telat jab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ini baru benar polisipengayomrakyat   jangan j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>polisi sambo budaya kekerasan om   bukankah in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>terkuak kenapa densi kebal hukum ternyata i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>kata bapak w polisi sewa uya kuya aja biar sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>apresiasi kecepatan polisi dalam mengusut per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets\n",
       "0       keren jokowi tangkap penjahat kakap kemaren a...\n",
       "1      dipikirpikir pantesan polisi tahuntahun belaka...\n",
       "2      setelah kasus sambo yang mayan ribet banyak  p...\n",
       "3      bubarkan  institusi  kepolisian  copot  kapolr...\n",
       "4       memang kalau jadi polisi baik karir telat jab...\n",
       "...                                                  ...\n",
       "9996   ini baru benar polisipengayomrakyat   jangan j...\n",
       "9997   polisi sambo budaya kekerasan om   bukankah in...\n",
       "9998      terkuak kenapa densi kebal hukum ternyata i...\n",
       "9999   kata bapak w polisi sewa uya kuya aja biar sam...\n",
       "10000   apresiasi kecepatan polisi dalam mengusut per...\n",
       "\n",
       "[10001 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clean\n",
    "df1_clean = df1\n",
    "df2_clean = df2\n",
    "\n",
    "df1_clean.to_csv('df1_clean.csv')\n",
    "df2_clean.to_csv('df2_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopword\n",
    "f = open(\"stopword_id.txt\", \"r\")\n",
    "stopword_list = []\n",
    "for line in f:\n",
    "    stripped_line = line.strip()\n",
    "    line_list = stripped_line.split()\n",
    "    stopword_list.append(line_list[0])\n",
    "f.close()\n",
    "\n",
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "tk = TweetTokenizer()\n",
    "df1_clean['tokenized_text'] = df1_clean['Tweets'].apply(tk.tokenize) \n",
    "df2_clean['tokenized_text'] = df2_clean['Tweets'].apply(tk.tokenize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sama mas saya pikir fokusnya sama bobroknya ke...</td>\n",
       "      <td>[sama, mas, saya, pikir, fokusnya, sama, bobro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haduh polisi lagi yg ditonjolkan polisi dah n...</td>\n",
       "      <td>[haduh, polisi, lagi, yg, ditonjolkan, polisi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>membuat konsorsium judi menjadi sindikat narko...</td>\n",
       "      <td>[membuat, konsorsium, judi, menjadi, sindikat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yg gak punya wibawa ya jokowi dan mempora ma...</td>\n",
       "      <td>[yg, gak, punya, wibawa, ya, jokowi, dan, memp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ditambah lg dgn tembakan gas air mata k tribun...</td>\n",
       "      <td>[ditambah, lg, dgn, tembakan, gas, air, mata, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>seuporter merasa benar turun k lapang kanjuruh...</td>\n",
       "      <td>[seuporter, merasa, benar, turun, k, lapang, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>penonton salah polisi salah  semuanya salah di...</td>\n",
       "      <td>[penonton, salah, polisi, salah, semuanya, sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>ini waktu  di gbt setelah persebaya kalah law...</td>\n",
       "      <td>[ini, waktu, di, gbt, setelah, persebaya, kala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>citra polisi indonesia bisa hancur jika kasus ...</td>\n",
       "      <td>[citra, polisi, indonesia, bisa, hancur, jika,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>tragedi kanjuruhan adalah akibat akumulasi kes...</td>\n",
       "      <td>[tragedi, kanjuruhan, adalah, akibat, akumulas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets  \\\n",
       "0      sama mas saya pikir fokusnya sama bobroknya ke...   \n",
       "1       haduh polisi lagi yg ditonjolkan polisi dah n...   \n",
       "2      membuat konsorsium judi menjadi sindikat narko...   \n",
       "3        yg gak punya wibawa ya jokowi dan mempora ma...   \n",
       "4      ditambah lg dgn tembakan gas air mata k tribun...   \n",
       "...                                                  ...   \n",
       "9996   seuporter merasa benar turun k lapang kanjuruh...   \n",
       "9997   penonton salah polisi salah  semuanya salah di...   \n",
       "9998    ini waktu  di gbt setelah persebaya kalah law...   \n",
       "9999   citra polisi indonesia bisa hancur jika kasus ...   \n",
       "10000  tragedi kanjuruhan adalah akibat akumulasi kes...   \n",
       "\n",
       "                                          tokenized_text  \n",
       "0      [sama, mas, saya, pikir, fokusnya, sama, bobro...  \n",
       "1      [haduh, polisi, lagi, yg, ditonjolkan, polisi,...  \n",
       "2      [membuat, konsorsium, judi, menjadi, sindikat,...  \n",
       "3      [yg, gak, punya, wibawa, ya, jokowi, dan, memp...  \n",
       "4      [ditambah, lg, dgn, tembakan, gas, air, mata, ...  \n",
       "...                                                  ...  \n",
       "9996   [seuporter, merasa, benar, turun, k, lapang, k...  \n",
       "9997   [penonton, salah, polisi, salah, semuanya, sal...  \n",
       "9998   [ini, waktu, di, gbt, setelah, persebaya, kala...  \n",
       "9999   [citra, polisi, indonesia, bisa, hancur, jika,...  \n",
       "10000  [tragedi, kanjuruhan, adalah, akibat, akumulas...  \n",
       "\n",
       "[10001 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_clean\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>keren jokowi tangkap penjahat kakap kemaren a...</td>\n",
       "      <td>[keren, jokowi, tangkap, penjahat, kakap, kema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dipikirpikir pantesan polisi tahuntahun belaka...</td>\n",
       "      <td>[dipikirpikir, pantesan, polisi, tahuntahun, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>setelah kasus sambo yang mayan ribet banyak  p...</td>\n",
       "      <td>[setelah, kasus, sambo, yang, mayan, ribet, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bubarkan  institusi  kepolisian  copot  kapolr...</td>\n",
       "      <td>[bubarkan, institusi, kepolisian, copot, kapol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>memang kalau jadi polisi baik karir telat jab...</td>\n",
       "      <td>[memang, kalau, jadi, polisi, baik, karir, tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>ini baru benar polisipengayomrakyat   jangan j...</td>\n",
       "      <td>[ini, baru, benar, polisipengayomrakyat, janga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>polisi sambo budaya kekerasan om   bukankah in...</td>\n",
       "      <td>[polisi, sambo, budaya, kekerasan, om, bukanka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>terkuak kenapa densi kebal hukum ternyata i...</td>\n",
       "      <td>[terkuak, kenapa, densi, kebal, hukum, ternyat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>kata bapak w polisi sewa uya kuya aja biar sam...</td>\n",
       "      <td>[kata, bapak, w, polisi, sewa, uya, kuya, aja,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>apresiasi kecepatan polisi dalam mengusut per...</td>\n",
       "      <td>[apresiasi, kecepatan, polisi, dalam, mengusut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10001 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets  \\\n",
       "0       keren jokowi tangkap penjahat kakap kemaren a...   \n",
       "1      dipikirpikir pantesan polisi tahuntahun belaka...   \n",
       "2      setelah kasus sambo yang mayan ribet banyak  p...   \n",
       "3      bubarkan  institusi  kepolisian  copot  kapolr...   \n",
       "4       memang kalau jadi polisi baik karir telat jab...   \n",
       "...                                                  ...   \n",
       "9996   ini baru benar polisipengayomrakyat   jangan j...   \n",
       "9997   polisi sambo budaya kekerasan om   bukankah in...   \n",
       "9998      terkuak kenapa densi kebal hukum ternyata i...   \n",
       "9999   kata bapak w polisi sewa uya kuya aja biar sam...   \n",
       "10000   apresiasi kecepatan polisi dalam mengusut per...   \n",
       "\n",
       "                                          tokenized_text  \n",
       "0      [keren, jokowi, tangkap, penjahat, kakap, kema...  \n",
       "1      [dipikirpikir, pantesan, polisi, tahuntahun, b...  \n",
       "2      [setelah, kasus, sambo, yang, mayan, ribet, ba...  \n",
       "3      [bubarkan, institusi, kepolisian, copot, kapol...  \n",
       "4      [memang, kalau, jadi, polisi, baik, karir, tel...  \n",
       "...                                                  ...  \n",
       "9996   [ini, baru, benar, polisipengayomrakyat, janga...  \n",
       "9997   [polisi, sambo, budaya, kekerasan, om, bukanka...  \n",
       "9998   [terkuak, kenapa, densi, kebal, hukum, ternyat...  \n",
       "9999   [kata, bapak, w, polisi, sewa, uya, kuya, aja,...  \n",
       "10000  [apresiasi, kecepatan, polisi, dalam, mengusut...  \n",
       "\n",
       "[10001 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove Stopword\n",
    "df1_clean['tokenized_text'] = [word for word in df1_clean['tokenized_text'] if not word in stopword_list]\n",
    "df2_clean['tokenized_text'] = [word for word in df2_clean['tokenized_text'] if not word in stopword_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisasi kata\n",
    "normalizad_word = pd.read_csv('normalisasi.csv')\n",
    "normalizad_word_dict = {}\n",
    "\n",
    "for index, row in normalizad_word.iterrows():\n",
    "    if row[0] not in normalizad_word_dict:\n",
    "        normalizad_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "\n",
    "df1_clean['tokenized_text'] = df1_clean['tokenized_text'].apply(normalized_term)\n",
    "df2_clean['tokenized_text'] = df2_clean['tokenized_text'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisasi kata\n",
    "alay_word = pd.read_csv('alay.csv')\n",
    "alay_word_dict = {}\n",
    "\n",
    "for index, row in alay_word.iterrows():\n",
    "    if row[0] not in alay_word_dict:\n",
    "        alay_word_dict[row[0]] = row[1] \n",
    "\n",
    "def normalized_term(document):\n",
    "    return [alay_word_dict[term] if term in alay_word_dict else term for term in document]\n",
    "\n",
    "df1_clean['tokenized_text'] = df1_clean['tokenized_text'].apply(normalized_term)\n",
    "df2_clean['tokenized_text'] = df2_clean['tokenized_text'].apply(normalized_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sama mas saya pikir fokusnya sama bobroknya ke...</td>\n",
       "      <td>[sama, mas, saya, pikir, fokusnya, sama, bobro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haduh polisi lagi yg ditonjolkan polisi dah n...</td>\n",
       "      <td>[aduh, polisi, lagi, yang, ditonjolkan, polisi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>membuat konsorsium judi menjadi sindikat narko...</td>\n",
       "      <td>[membuat, konsorsium, judi, menjadi, sindikat,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yg gak punya wibawa ya jokowi dan mempora ma...</td>\n",
       "      <td>[yang, tidak, punya, wibawa, iya, jokowi, dan,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ditambah lg dgn tembakan gas air mata k tribun...</td>\n",
       "      <td>[ditambah, lagi, dengan, tembakan, gas, air, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>ini baru benar polisipengayomrakyat   jangan j...</td>\n",
       "      <td>[ini, baru, benar, polisipengayomrakyat, janga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>polisi sambo budaya kekerasan om   bukankah in...</td>\n",
       "      <td>[polisi, sambo, budaya, kekerasan, om, bukanka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>terkuak kenapa densi kebal hukum ternyata i...</td>\n",
       "      <td>[terkuak, kenapa, densi, kebal, hukum, ternyat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>kata bapak w polisi sewa uya kuya aja biar sam...</td>\n",
       "      <td>[kata, bapak, aku, polisi, sewa, uya, kuya, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001</th>\n",
       "      <td>apresiasi kecepatan polisi dalam mengusut per...</td>\n",
       "      <td>[apresiasi, kecepatan, polisi, dalam, mengusut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20002 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets  \\\n",
       "0      sama mas saya pikir fokusnya sama bobroknya ke...   \n",
       "1       haduh polisi lagi yg ditonjolkan polisi dah n...   \n",
       "2      membuat konsorsium judi menjadi sindikat narko...   \n",
       "3        yg gak punya wibawa ya jokowi dan mempora ma...   \n",
       "4      ditambah lg dgn tembakan gas air mata k tribun...   \n",
       "...                                                  ...   \n",
       "19997  ini baru benar polisipengayomrakyat   jangan j...   \n",
       "19998  polisi sambo budaya kekerasan om   bukankah in...   \n",
       "19999     terkuak kenapa densi kebal hukum ternyata i...   \n",
       "20000  kata bapak w polisi sewa uya kuya aja biar sam...   \n",
       "20001   apresiasi kecepatan polisi dalam mengusut per...   \n",
       "\n",
       "                                          tokenized_text  \n",
       "0      [sama, mas, saya, pikir, fokusnya, sama, bobro...  \n",
       "1      [aduh, polisi, lagi, yang, ditonjolkan, polisi...  \n",
       "2      [membuat, konsorsium, judi, menjadi, sindikat,...  \n",
       "3      [yang, tidak, punya, wibawa, iya, jokowi, dan,...  \n",
       "4      [ditambah, lagi, dengan, tembakan, gas, air, m...  \n",
       "...                                                  ...  \n",
       "19997  [ini, baru, benar, polisipengayomrakyat, janga...  \n",
       "19998  [polisi, sambo, budaya, kekerasan, om, bukanka...  \n",
       "19999  [terkuak, kenapa, densi, kebal, hukum, ternyat...  \n",
       "20000  [kata, bapak, aku, polisi, sewa, uya, kuya, sa...  \n",
       "20001  [apresiasi, kecepatan, polisi, dalam, mengusut...  \n",
       "\n",
       "[20002 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df1_clean, df2_clean]\n",
    "data = pd.concat(frames, ignore_index=True, sort=False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "# import Sastrawi package\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import swifter\n",
    "\n",
    "\n",
    "# create stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# stemmed\n",
    "def stemmed_wrapper(term):\n",
    "    return stemmer.stem(term)\n",
    "\n",
    "term_dict = {}\n",
    "\n",
    "for document in data['tokenized_text']:\n",
    "    for term in document:\n",
    "        if term not in term_dict:\n",
    "            term_dict[term] = ' '\n",
    "            \n",
    "print(len(term_dict))\n",
    "print(\"------------------------\")\n",
    "\n",
    "for term in term_dict:\n",
    "    term_dict[term] = stemmed_wrapper(term)\n",
    "    print(term,\":\" ,term_dict[term])\n",
    "    \n",
    "# # apply stemmed term to dataframe\n",
    "def get_stemmed_term(document):\n",
    "    return [term_dict[term] for term in document]\n",
    "\n",
    "data['tweet_tokens_stemmed'] = data['tokenized_text'].swifter.apply(get_stemmed_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('after_stemmed.csv')\n",
    "data_twitt= pd.read_csv('after_stemmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopword\n",
    "f = open(\"stopword_id.txt\", \"r\")\n",
    "stopword_list = []\n",
    "for line in f:\n",
    "    stripped_line = line.strip()\n",
    "    line_list = stripped_line.split()\n",
    "    stopword_list.append(line_list[0])\n",
    "f.close()\n",
    "\n",
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "stop_factory = StopWordRemoverFactory()\n",
    "stopword = stop_factory.create_stop_word_remover()\n",
    "\n",
    "data_twitt['clean'] = [word for word in data_twitt['tweet_tokens_stemmed'] if not word in stopword_list]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e9dca4b9b8d0934cbb1cdf5b5a6e4b74d31753c1e821af49a36eb33015b9e17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
